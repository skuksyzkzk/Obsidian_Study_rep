---
cssclasses:
  - dashboard
---

![[1주차(답변).pdf]]

> 매주 질의응답을 먼저하고 그다음 실습을 진행한다 
   다음주부터 실습진행 
   이번주는 실습 x 

지금 AI를 만든 것 ML
기계 학습 

### ML의 핵심 task는?
> Classification (분류)

정리를 잘하는 게 중요하다 

어지간한 classification을 할 줄 알게 만드는 게 이 수업 목적 

공학도는 결국 blackbox에 input을 넣으면 oupt이 나오는 것 

![[Drawing 2024-03-11 13.29.57.excalidraw]]

사람들의 니즈가 먼저다 기술보다 

상품기획자들  
- input을 넣으면 이런 output이 나오면 사람들이 좋아할것같다

R&D팀(공학도들) research and development
- blackbox를 만드는 역할  기술을 사용해서 내부 로직을 구현한다

분류가 되면 그 기계를 classifier라고 한다 분류기 

> classifier ( 분류기 )


### classifier의 input은?

> obj

- image
- text - 자연어처리
- voice so on
- 내가 분류하고자 하는 모든 것

### output?
> class

원래 categorization이 였다 classification이 

class도 category 같은 것

- text면 topic이 가능 ) 정치,스포츠
- 감정 ) 긍정 부정 
- 이미지 ) object detection을 한 뒤 classification을 한다
	- detection후 사람이냐 동물이냐를 classification한다

아무리 복잡한 거라도 classification 가능 존재

>classification을 general하게 modeling이라고 한다

원래는 파이프라인 처럼 나누어져서 돌아가게 만들어져 있었다
기계학습에선

그러나 Deep learning에선 판세가 바뀌었다.

> end-to-end 

안이 쪼개져있지 않다 

model하나가 들어가면 하나가 통째로 나온다 

앞에서 오류가나면 뒤쪽다 다 틀리는 error -propagation이 발생 할 수있다 => 파이프라이닝에서

하지만 처음부터 학습해서 하도록 만들었기에 end-to-end가 error발생할 가능성 적다

모듈을 2개로 나눌 수 있다

1. **data representation 데이터 표현** (오늘 주제)
	1. 인풋을 데이터 표현해서 모델이 이해할수있도록 만드는 것
	2. 그래서 이게 모델안에 들어올수도 밖에 나갈수도
	3. 응용하는 사람들이 여기에 focus 
	4. 학부생 수준에선 model만들기가 거의 불가능 데이터 표현에 집중
2. classifier ( model )
	1. 신경망 svm 이런것들이 여기에 속한다
	2. 인공지능을 연구하는 연구자를 나누면 순수하게 모델을 연구하는 사람들이 있다/응용(application)쪽이 vision,자연어처리

## Deap Learning

신경망이 딥러닝이 된 것 

> input은 vector다 output도 vector다 

#### 인공지능에서 input은 vector다 !!

input vector를 어떻게 만들고 왜 만드는게 중요한지 오늘

> matrix 곱 연산이 기본 연산이고 메인이다

# 질문 

## 1. oov처리에 대한 질문

out of vocabulary (어휘)

> 어휘 밖에 있다 => 학습할 때 보지 못했던 단어가 밖으로 나오면 테스트 할 때
> 

결국 모든 단어를 학습시킬수없기에 
### 지식 표현 방법의 차이
최초의 컴퓨터도 결국 전쟁 때문에 만들어짐 포병
> 계산을 빠르게 하기 위함 !!

컴퓨터는 주로 숫자를 다루고 사람은 symbol을 다룬다

컴퓨터는 기본적으로 십진수를 처리하지 않고 이진수를 처리한다

하지만 AI는 world knowledge를 처리 해야된다

word는 의미를 가지고 있고 이거를 파악해야 W.K를 잘 표현

#### 인공지능 컴퓨터는 얼마나 의미를 잘 파악하느냐

문자열 중에 사전에 들어간 것이 word ) apple

string은 어느 알파벳 시퀀스가 다 가능 ) ksyzkzk

시스템이 다룰 수 있는 총 word = vocabulary 

> 이것을 벗어난 것이 OOV

결국 word를 숫자로 표현해야되는게 그것을 잘표현하기 위한 것이 

> vector 

숫자 여러 개로 의미를 표현 할 수 있게 하는 것

## 데이터 표현이란?
> input을 잘 처리해서 vector로 표현 


### 이전과 지금의 데이터 표현 차이

1. 예전
	1. one-hot representation
		1. 각각에 대응하는 vector를 만든다
		2. 단어가 5개 나왔으면 5차원 vector 
		3. back of word방식이라고 불렸다
		4. 문서하나 (D1)을 one-hot  표현이 아니라 단어 하나가 one-hot으로 표현한것
		5. 단어의 합집합이 문서 하나 
		6. *문제*
			1. very sparse -> 안좋다 메모리 낭비 0이 너무 많아서 
			2. very high dimensionality 
				1. 1억개 단어면 1억차원 하지만 10개만 쓰이면 나머지가 0 그래서 또 very sparse해지는 것 
				2. 단어가 커지면 안된다 처리가 
2. Neural Word Embedding
		1. 값이 다 실수 모든 dimension의 값을 넣을 수 있다
		2. 파워가 훨씬 커짐 
		3. 사실 onehot은 축에 있는 값만 쓰지 나머지는 못쓴다 
			1. ![[Drawing 2024-03-11 xyz]]
				1. (1,0,0)
		5. 그래서 dense한게 representaition이 훨씬 좋은 것 
		6. Large Language Model = LLM

> ELMo- Embeddings from Language Model 이게 문맥으로 하는것 

polysemous - 다의어

word embedding의 문제점
단어마다 representation을 만드면 문제점은?
- 사전의 단어 뜻이 하나만 있는 것이 없다 다 여러개
- example) 배 -> 사람배 먹는배 타는배
- need a fan 에서 fan이 뜻이 2개 
- 어떻게 뜻이 다른데 vector가 똑같을 수가 있냐
- 어떻게 뜻을 구분할까? => 문맥 ( *context* )
- vector를 문장이 들어올때마다 실시간으로 만들어보자 !!!
- 그 파라미터를 계산해야되니다 그게 벌트 그게 발전해서 LLM가 만들어 진것 

## 2. 한국어 LLM

언어처리가 어려운게 거기에 문화 사회적인 것이 전부 있으니 

한국어가 어렵다!!

투입가능 자원 부족 -> 돈이 많이 든다

# 추가 질문
1. 이미지는 n by n이 아닌가요>
matrix는 vector가 쌓여있는 것 


# 온라인 강의

![[01-AI_intro.pdf]]


인공지능은 결국 사람이 하는 것을 하는것 
그래서 게임에 많이 시도 
보드게임이 적용이 쉽고

최종목표는 바둑 GO 였음 


# Heuristic Search 
이거의 핵심은 Scoring이 가능해야한다

내가 점수를 부여해서 유리한 쪽으로 진행시키는것 

인공지능에서 다르는 자료구조는 트리나 그래프는 굉장히 크다 
사이즈가 
속도가 중요하기에 서치를 할때도 내가 원하는 스테이츠나 놀리지가 있을만한 곳을 찿아가야된다 